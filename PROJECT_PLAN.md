# Matrix Game 2.0 Apple Silicon é©é…è¨ˆåŠƒ (æœ€çµ‚ç‰ˆ)
*çµåˆå¯¦ä½œæ€§å’ŒæŠ€è¡“åˆ†æžçš„å¹³è¡¡æ–¹æ¡ˆ*

## ðŸŽ¯ é …ç›®ç›®æ¨™
å¾žæŠ€è¡“åˆ†æžå‡ºç™¼ï¼Œå¯¦ä½œ Matrix Game 2.0 çš„ Apple Silicon é©é…ç‰ˆæœ¬ï¼Œé‡è¦–å¯¦æ¸¬å’Œå¯æ¢å¾©æ€§

## ðŸ“ å°ˆæ¡ˆçµæ§‹ä¿è­·ç­–ç•¥
**åŽŸå‰‡ï¼šæ¯æ¬¡å¯¦é©—éƒ½è¦å¯ä»¥å¿«é€Ÿå›žæ»¾ï¼Œä¸ç ´å£žå°ˆæ¡ˆçµæ§‹**

```
matrix-game-2.0/
â”œâ”€â”€ Matrix-Game-Original/          # åŽŸå§‹ä»£ç¢¼ï¼ˆåªè®€ï¼Œæ°¸ä¸ä¿®æ”¹ï¼‰
â”œâ”€â”€ Matrix-Game/                   # ç¾æœ‰çè²´æ–‡ä»¶ï¼ˆä¿è­·ï¼‰
â”œâ”€â”€ experiments/                   # å¯¦é©—ç›®éŒ„ï¼ˆå¯éš¨æ„åˆªé™¤é‡å»ºï¼‰
â”‚   â”œâ”€â”€ exp-01-flash-attention/
â”‚   â”œâ”€â”€ exp-02-mps-datatype/
â”‚   â””â”€â”€ exp-03-device-management/
â”œâ”€â”€ Matrix-Game-Working/           # æœ€çµ‚å·¥ä½œç‰ˆæœ¬
â””â”€â”€ test-results/                  # æ¸¬è©¦çµæžœè¨˜éŒ„
```

## ðŸ§ª å¯¦é©—é©…å‹•çš„é–‹ç™¼æµç¨‹

### éšŽæ®µ 1ï¼šå»ºç«‹å¯¦é©—ç’°å¢ƒï¼ˆä¿è­·ç¾æœ‰çµæ§‹ï¼‰

#### æ­¥é©Ÿ 1.1ï¼šå»ºç«‹å®‰å…¨çš„å¯¦é©—ç©ºé–“
```bash
# å»ºç«‹å¯¦é©—ç›®éŒ„çµæ§‹
mkdir -p experiments test-results

# å»ºç«‹ä¹¾æ·¨çš„å·¥ä½œåŸºç¤Žï¼ˆå¾žåŽŸå§‹ç¢¼è¤‡è£½ï¼‰
cp -r Matrix-Game-Original/Matrix-Game-2 ./experiments/base-clean
cd experiments/base-clean

# ä¿è­·æ€§è¤‡è£½çè²´æ–‡æª”
cp ../../Matrix-Game/Matrix-Game-2/README_Apple_Silicon.md ./

# å»ºç«‹å¿«é€Ÿé‡ç½®è…³æœ¬
cat > ../reset-experiment.sh << 'EOF'
#!/bin/bash
EXPERIMENT_NAME=$1
rm -rf experiments/${EXPERIMENT_NAME}
cp -r experiments/base-clean experiments/${EXPERIMENT_NAME}
echo "å¯¦é©—ç’°å¢ƒ ${EXPERIMENT_NAME} å·²é‡ç½®"
EOF
chmod +x ../reset-experiment.sh
```

#### æ­¥é©Ÿ 1.2ï¼šå»ºç«‹æœ€å°æ¸¬è©¦ç”¨ä¾‹
**ç›®çš„**ï¼šåœ¨ä¿®æ”¹ä»»ä½•ä»£ç¢¼å‰ï¼Œå…ˆæœ‰ä¸€å€‹å¯ä»¥å¿«é€Ÿé©—è­‰çš„åŸºæº–æ¸¬è©¦

```bash
# å»ºç«‹æœ€å°æ¸¬è©¦è…³æœ¬
cat > test-minimal.py << 'EOF'
#!/usr/bin/env python3
"""æœ€å°åŒ–æ¸¬è©¦ï¼šæª¢æŸ¥æ ¸å¿ƒæ¨¡çµ„æ˜¯å¦å¯ä»¥å°Žå…¥å’Œåˆå§‹åŒ–"""
import torch
import sys
import traceback

def test_import():
    """æ¸¬è©¦åŸºæœ¬å°Žå…¥"""
    try:
        from wan.modules.action_module import ActionModule
        from wan.modules.model import WanModel
        from pipeline.causal_inference import CausalInferencePipeline
        print("âœ… åŸºæœ¬å°Žå…¥æ¸¬è©¦é€šéŽ")
        return True
    except Exception as e:
        print(f"âŒ å°Žå…¥å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_device_detection():
    """æ¸¬è©¦è¨­å‚™æª¢æ¸¬"""
    print(f"MPS å¯ç”¨: {torch.backends.mps.is_available()}")
    print(f"MPS å·²å»ºç½®: {torch.backends.mps.is_built()}")
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"å°‡ä½¿ç”¨è¨­å‚™: {device}")
    
    # æ¸¬è©¦åŸºæœ¬å¼µé‡æ“ä½œ
    try:
        x = torch.randn(10, 10).to(device)
        y = torch.matmul(x, x.T)
        print("âœ… åŸºæœ¬å¼µé‡æ“ä½œé€šéŽ")
        return True
    except Exception as e:
        print(f"âŒ å¼µé‡æ“ä½œå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("é–‹å§‹æœ€å°åŒ–æ¸¬è©¦...")
    success = test_import() and test_device_detection()
    sys.exit(0 if success else 1)
EOF
```

### éšŽæ®µ 2ï¼šé€å€‹æŠ€è¡“é»žå¯¦é©—ï¼ˆæ¯å€‹å¯¦é©—ç¨ç«‹å¯å›žæ»¾ï¼‰

#### å¯¦é©— 2.1ï¼šFlash Attention æ›¿ä»£æ–¹æ¡ˆæ¸¬è©¦

```bash
# å»ºç«‹å¯¦é©—ç’°å¢ƒ
../reset-experiment.sh exp-01-flash-attention
cd ../exp-01-flash-attention

# å»ºç«‹ A/B æ¸¬è©¦è…³æœ¬
cat > test-attention-methods.py << 'EOF'
import torch
import time
from typing import Callable

def test_attention_method(attention_func: Callable, name: str, q, k, v):
    """æ¸¬è©¦æ³¨æ„åŠ›æ–¹æ³•çš„æ•ˆèƒ½å’Œæ­£ç¢ºæ€§"""
    print(f"\næ¸¬è©¦ {name}:")
    
    try:
        start_time = time.time()
        result = attention_func(q, k, v)
        end_time = time.time()
        
        print(f"  âœ… åŸ·è¡ŒæˆåŠŸ")
        print(f"  â±ï¸  åŸ·è¡Œæ™‚é–“: {end_time - start_time:.4f}s")
        print(f"  ðŸ“Š è¼¸å‡ºå½¢ç‹€: {result.shape}")
        print(f"  ðŸ“ˆ è¨˜æ†¶é«”ä½¿ç”¨: {torch.mps.current_allocated_memory() / 1024**2:.1f}MB")
        
        return result, True
    except Exception as e:
        print(f"  âŒ åŸ·è¡Œå¤±æ•—: {e}")
        return None, False

# å®šç¾©ä¸åŒçš„æ³¨æ„åŠ›å¯¦ç¾
def pytorch_native_attention(q, k, v):
    """PyTorch 2.0 åŽŸç”Ÿå¯¦ç¾"""
    return torch.nn.functional.scaled_dot_product_attention(q, k, v)

def manual_attention(q, k, v):
    """æ‰‹å‹•å¯¦ç¾ï¼ˆREADME æ–¹æ¡ˆï¼‰"""
    scale = q.size(-1) ** -0.5
    attention = torch.matmul(q * scale, k.transpose(-2, -1))
    attention = torch.softmax(attention, dim=-1)
    return torch.matmul(attention, v)

def run_attention_comparison():
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    
    # æ¸¬è©¦æ•¸æ“š
    batch_size, seq_len, dim = 2, 128, 64
    q = torch.randn(batch_size, seq_len, dim, device=device)
    k = torch.randn(batch_size, seq_len, dim, device=device)  
    v = torch.randn(batch_size, seq_len, dim, device=device)
    
    results = {}
    
    # æ¸¬è©¦æ‰€æœ‰æ–¹æ³•
    methods = [
        (pytorch_native_attention, "PyTorch åŽŸç”Ÿ"),
        (manual_attention, "æ‰‹å‹•å¯¦ç¾")
    ]
    
    for method, name in methods:
        result, success = test_attention_method(method, name, q, k, v)
        if success:
            results[name] = result
    
    # æ¯”è¼ƒçµæžœä¸€è‡´æ€§
    if len(results) > 1:
        print("\nçµæžœä¸€è‡´æ€§æª¢æŸ¥:")
        base_result = list(results.values())[0]
        for name, result in results.items():
            diff = torch.abs(base_result - result).mean().item()
            print(f"  {name}: å¹³å‡å·®ç•° {diff:.6f}")
    
    return results

if __name__ == "__main__":
    run_attention_comparison()
EOF
```

**å¯¦é©—åŸ·è¡Œå’Œè¨˜éŒ„**ï¼š
```bash
# åŸ·è¡Œå¯¦é©—
python test-attention-methods.py > ../../test-results/exp-01-attention-$(date +%Y%m%d_%H%M%S).log 2>&1

# æ ¹æ“šçµæžœæ±ºå®šæœ€ä½³æ–¹æ¡ˆï¼Œç„¶å¾Œä¿®æ”¹ä»£ç¢¼
# å¦‚æžœå¯¦é©—å¤±æ•—ï¼Œç›´æŽ¥é‡ç½®ç’°å¢ƒï¼š../reset-experiment.sh exp-01-flash-attention
```

#### å¯¦é©— 2.2ï¼šMPS æ•¸æ“šé¡žåž‹æœ€ä½³åŒ–æ¸¬è©¦

```bash
../reset-experiment.sh exp-02-mps-datatype  
cd ../exp-02-mps-datatype

cat > test-precision-impact.py << 'EOF'
import torch
import numpy as np

def test_sinusoidal_precision():
    """æ¸¬è©¦ sinusoidal embedding çš„ç²¾åº¦å½±éŸ¿"""
    def sinusoidal_float64(dim, position):
        position = position.type(torch.float64)
        # ... å¯¦ç¾

    def sinusoidal_float32(dim, position):
        position = position.type(torch.float32) 
        # ... å¯¦ç¾

    def sinusoidal_smart(dim, position):
        """æ™ºèƒ½ç²¾åº¦ï¼šæ ¹æ“šè¨­å‚™é¸æ“‡"""
        if position.device.type == 'mps':
            position = position.type(torch.float32)
        else:
            position = position.type(torch.float64)
        # ... å¯¦ç¾

    # A/B/C æ¸¬è©¦æ‰€æœ‰æ–¹æ¡ˆ
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    test_positions = torch.arange(100, device=device)
    
    results = {}
    for name, func in [("Float64", sinusoidal_float64), 
                       ("Float32", sinusoidal_float32),
                       ("Smart", sinusoidal_smart)]:
        try:
            start_time = time.time()
            result = func(128, test_positions)
            end_time = time.time()
            results[name] = {
                'result': result,
                'time': end_time - start_time,
                'success': True
            }
            print(f"âœ… {name}: {end_time - start_time:.4f}s")
        except Exception as e:
            results[name] = {'success': False, 'error': str(e)}
            print(f"âŒ {name}: {e}")
    
    # ç²¾åº¦æ¯”è¼ƒ
    if results['Float64']['success'] and results['Float32']['success']:
        diff = torch.abs(results['Float64']['result'] - results['Float32']['result']).mean()
        print(f"Float32 vs Float64 ç²¾åº¦å·®ç•°: {diff.item():.8f}")
    
    return results
EOF
```

#### å¯¦é©— 2.3ï¼šæ•´åˆæ¸¬è©¦å’ŒåŸºæº–å»ºç«‹

```bash
../reset-experiment.sh exp-03-integration
cd ../exp-03-integration

# æ‡‰ç”¨æ‰€æœ‰é€šéŽå¯¦é©—çš„ä¿®æ”¹
# å»ºç«‹å®Œæ•´çš„åŸºæº–æ¸¬è©¦

cat > test-full-pipeline.py << 'EOF'
#!/usr/bin/env python3
"""å®Œæ•´ç®¡é“æ¸¬è©¦ï¼šæ¨¡æ“¬çœŸå¯¦ä½¿ç”¨æƒ…å¢ƒ"""

def test_minimal_inference():
    """æœ€å°æŽ¨ç†æ¸¬è©¦ï¼šä¸éœ€è¦å¤§æ¨¡åž‹ï¼Œåªæ¸¬è©¦ä»£ç¢¼è·¯å¾‘"""
    try:
        # ä½¿ç”¨æœ€å°åƒæ•¸å»ºç«‹æ¨¡åž‹
        # åŸ·è¡Œä¸€æ¬¡ forward pass
        # è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨ã€åŸ·è¡Œæ™‚é–“
        # é©—è­‰è¼¸å‡ºå½¢ç‹€æ­£ç¢º
        pass
    except Exception as e:
        print(f"æŽ¨ç†æ¸¬è©¦å¤±æ•—: {e}")
        return False
    return True

def test_memory_limits():
    """è¨˜æ†¶é«”é™åˆ¶æ¸¬è©¦ï¼šç¢ºä¿ä¸è¶…éŽ 18GB"""
    # ç›£æŽ§è¨˜æ†¶é«”ä½¿ç”¨
    # æ¸¬è©¦é‚Šç•Œæ¢ä»¶
    pass

def run_benchmark():
    """åŸ·è¡Œå®Œæ•´åŸºæº–æ¸¬è©¦"""
    results = {
        'inference_success': test_minimal_inference(),
        'memory_within_limits': test_memory_limits(),
        'timestamp': time.time()
    }
    
    # è¨˜éŒ„åˆ°çµæžœæ–‡ä»¶
    with open('../../test-results/benchmark.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    return all(results.values())
EOF
```

### éšŽæ®µ 3ï¼šå»ºç«‹æœ€çµ‚å·¥ä½œç‰ˆæœ¬

```bash
# åªæœ‰æ‰€æœ‰å¯¦é©—éƒ½é€šéŽï¼Œæ‰å»ºç«‹æœ€çµ‚ç‰ˆæœ¬
if [ -f "test-results/all-experiments-passed" ]; then
    cp -r experiments/exp-03-integration ./Matrix-Game-Working
    echo "âœ… æœ€çµ‚å·¥ä½œç‰ˆæœ¬å»ºç«‹å®Œæˆ"
else
    echo "âŒ å¯¦é©—å°šæœªå…¨éƒ¨é€šéŽï¼Œä¸å»ºç«‹æœ€çµ‚ç‰ˆæœ¬"
fi
```

## ðŸ”„ æ•…éšœæ¢å¾©æ©Ÿåˆ¶

### å¿«é€Ÿé‡ç½®å‘½ä»¤
```bash
# é‡ç½®å–®å€‹å¯¦é©—
./experiments/reset-experiment.sh exp-01-flash-attention

# é‡ç½®æ‰€æœ‰å¯¦é©—
rm -rf experiments/exp-* && echo "æ‰€æœ‰å¯¦é©—å·²é‡ç½®"

# å›žåˆ°å®‰å…¨ç‹€æ…‹
rm -rf Matrix-Game-Working experiments/exp-*
echo "å·²å›žåˆ°å®‰å…¨ç‹€æ…‹ï¼Œåªä¿ç•™åŽŸå§‹ä»£ç¢¼å’Œçè²´æ–‡æª”"
```

### å¯¦é©—è¨˜éŒ„å’Œè¿½è¹¤
æ¯æ¬¡å¯¦é©—éƒ½æœƒç”¢ç”Ÿï¼š
- æ™‚é–“æˆ³æ¨™è¨˜çš„æ—¥èªŒæ–‡ä»¶
- JSON æ ¼å¼çš„æ¸¬è©¦çµæžœ
- æ•ˆèƒ½åŸºæº–æ•¸æ“š
- å¤±æ•—æ™‚çš„å®Œæ•´ traceback

## ðŸŽ¯ æˆåŠŸæ¨™æº–ï¼ˆåŸºæ–¼å¯¦æ¸¬ï¼‰

æ¯å€‹å¯¦é©—éšŽæ®µå¿…é ˆé”åˆ°ï¼š
- âœ… **åŠŸèƒ½æ¸¬è©¦**: åŸºæœ¬ import å’Œåˆå§‹åŒ–æˆåŠŸ
- âœ… **ç›¸å®¹æ€§æ¸¬è©¦**: åœ¨ MPS è¨­å‚™ä¸Šæ­£å¸¸é‹è¡Œ
- âœ… **ç²¾åº¦æ¸¬è©¦**: æ•¸å€¼å·®ç•°åœ¨å¯æŽ¥å—ç¯„åœå…§
- âœ… **æ•ˆèƒ½æ¸¬è©¦**: åŸ·è¡Œæ™‚é–“åˆç†
- âœ… **è¨˜æ†¶é«”æ¸¬è©¦**: ä¸è¶…éŽ 18GB é™åˆ¶

## ðŸ“Š å¯¦é©—æ±ºç­–çŸ©é™£

| æŠ€è¡“é»ž | æ–¹æ¡ˆA | æ–¹æ¡ˆB | æ–¹æ¡ˆC | é¸æ“‡æ¨™æº– |
|--------|-------|-------|-------|----------|
| Flash Attention | PyTorchåŽŸç”Ÿ | æ‰‹å‹•å¯¦ç¾ | æ··åˆç­–ç•¥ | æ•ˆèƒ½+ç©©å®šæ€§ |
| MPSæ•¸æ“šé¡žåž‹ | å…¨Float32 | æ™ºèƒ½åˆ‡æ› | MPSåŽŸç”Ÿ | ç²¾åº¦+ç›¸å®¹æ€§ |
| è¨­å‚™ç®¡ç† | ç°¡å–®if-else | æ™ºèƒ½ç®¡ç†å™¨ | ç¡¬ç·¨ç¢¼ | ç°¡å–®+æœ‰æ•ˆ |

**åŽŸå‰‡ï¼šå¯¦æ¸¬å‹éŽç†è«–ï¼Œç°¡å–®å‹éŽè¤‡é›œï¼Œå¯æ¢å¾©å‹éŽå®Œç¾Ž**