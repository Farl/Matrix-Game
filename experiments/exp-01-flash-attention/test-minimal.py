#!/usr/bin/env python3
"""æœ€å°åŒ–æ¸¬è©¦ï¼šæª¢æŸ¥æ ¸å¿ƒæ¨¡çµ„æ˜¯å¦å¯ä»¥å°å…¥å’Œåˆå§‹åŒ–"""
import torch
import sys
import traceback
import os

def test_import():
    """æ¸¬è©¦åŸºæœ¬å°å…¥"""
    print("ğŸ§ª æ¸¬è©¦æ¨¡çµ„å°å…¥...")
    try:
        # æ·»åŠ ç•¶å‰ç›®éŒ„åˆ° Python path
        sys.path.insert(0, os.getcwd())
        
        from wan.modules.action_module import ActionModule
        print("  âœ… ActionModule å°å…¥æˆåŠŸ")
        
        # æ¸¬è©¦ ActionModule åˆå§‹åŒ–
        action_module = ActionModule(mouse_dim_in=2, keyboard_dim_in=6)
        print("  âœ… ActionModule åˆå§‹åŒ–æˆåŠŸ")
        
        from wan.modules.model import WanModel
        print("  âœ… WanModel å°å…¥æˆåŠŸ")
        
        from pipeline.causal_inference import get_current_action
        print("  âœ… causal_inference å°å…¥æˆåŠŸ")
        
        print("âœ… åŸºæœ¬å°å…¥æ¸¬è©¦é€šé")
        return True
    except Exception as e:
        print(f"âŒ å°å…¥å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_device_detection():
    """æ¸¬è©¦è¨­å‚™æª¢æ¸¬"""
    print("\nğŸ” æ¸¬è©¦è¨­å‚™æª¢æ¸¬...")
    print(f"  PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"  MPS å¯ç”¨: {torch.backends.mps.is_available()}")
    print(f"  MPS å·²å»ºç½®: {torch.backends.mps.is_built()}")
    
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"  å°‡ä½¿ç”¨è¨­å‚™: {device}")
    
    # æ¸¬è©¦åŸºæœ¬å¼µé‡æ“ä½œ
    try:
        print("  æ¸¬è©¦åŸºæœ¬å¼µé‡æ“ä½œ...")
        x = torch.randn(10, 10).to(device)
        y = torch.matmul(x, x.T)
        print(f"  å¼µé‡å½¢ç‹€: {y.shape}")
        print("âœ… åŸºæœ¬å¼µé‡æ“ä½œé€šé")
        return True
    except Exception as e:
        print(f"âŒ å¼µé‡æ“ä½œå¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_flash_attention_current_state():
    """æ¸¬è©¦ç•¶å‰ Flash Attention ç‹€æ…‹"""
    print("\nâš¡ æ¸¬è©¦ Flash Attention ç•¶å‰ç‹€æ…‹...")
    try:
        from flash_attn import flash_attn_func
        print("âœ… Flash Attention å¯ç”¨")
        return True
    except ImportError as e:
        print(f"âŒ Flash Attention ä¸å¯ç”¨: {e}")
        return False

def test_original_requirements():
    """æ¸¬è©¦åŸå§‹ requirements åœ¨ Apple Silicon ä¸Šçš„ç›¸å®¹æ€§"""
    print("\nğŸ“¦ æ¸¬è©¦é—œéµä¾è³´...")
    
    # æª¢æŸ¥ NVIDIA ç›¸é—œä¾è³´çš„ç‹€æ…‹
    nvidia_deps = ["nvidia-pyindex", "nvidia-tensorrt", "pycuda"]
    for dep in nvidia_deps:
        try:
            __import__(dep.replace("-", "_"))
            print(f"  âš ï¸  {dep} å·²å®‰è£ï¼ˆå¯èƒ½æœƒæœ‰å•é¡Œï¼‰")
        except ImportError:
            print(f"  âœ… {dep} æœªå®‰è£ï¼ˆç¬¦åˆé æœŸï¼‰")
    
    # æª¢æŸ¥é—œéµä¾è³´
    key_deps = ["torch", "diffusers", "transformers", "accelerate"]
    for dep in key_deps:
        try:
            module = __import__(dep)
            version = getattr(module, "__version__", "unknown")
            print(f"  âœ… {dep}: {version}")
        except ImportError:
            print(f"  âŒ {dep} æœªå®‰è£")
            return False
    
    return True

if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹æœ€å°åŒ–æ¸¬è©¦...")
    print("=" * 50)
    
    tests = [
        ("è¨­å‚™æª¢æ¸¬", test_device_detection),
        ("ä¾è³´æª¢æŸ¥", test_original_requirements),
        ("Flash Attentionç‹€æ…‹", test_flash_attention_current_state),
        ("æ¨¡çµ„å°å…¥", test_import),
    ]
    
    results = {}
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ åŸ·è¡Œæ¸¬è©¦: {test_name}")
        results[test_name] = test_func()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½è¦½:")
    for test_name, result in results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"  {test_name}: {status}")
    
    overall_success = all(results.values())
    print(f"\nğŸ¯ ç¸½é«”çµæœ: {'âœ… æ‰€æœ‰æ¸¬è©¦é€šé' if overall_success else 'âŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—'}")
    
    sys.exit(0 if overall_success else 1)